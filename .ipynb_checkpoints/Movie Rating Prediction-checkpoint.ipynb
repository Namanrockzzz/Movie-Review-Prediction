{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorrect-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-martin",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metric-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-controversy",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "played-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "modified-feeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mature intelligent and highly charged melodram...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://video.google.com/videoplay?docid=211772...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: Opera (1987) Director: Dario Argento Ca...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think a lot of people just wrote this off as...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a story of two dogs and a cat looking ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  mature intelligent and highly charged melodram...   pos\n",
       "1  http://video.google.com/videoplay?docid=211772...   pos\n",
       "2  Title: Opera (1987) Director: Dario Argento Ca...   pos\n",
       "3  I think a lot of people just wrote this off as...   pos\n",
       "4  This is a story of two dogs and a cat looking ...   pos"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coordinated-dependence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember those old kung fu movies we used to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is another one on my List of Movies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How in the world does a thing like this get in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Queen of the Damned\" is one of the best vampi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Caprica episode (S01E01) is well done as a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Remember those old kung fu movies we used to w...\n",
       "1  This movie is another one on my List of Movies...\n",
       "2  How in the world does a thing like this get in...\n",
       "3  \"Queen of the Damned\" is one of the best vampi...\n",
       "4  The Caprica episode (S01E01) is well done as a..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-nancy",
   "metadata": {},
   "source": [
    "### x_train, y_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "premier-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.values[:,0]\n",
    "y_train = train.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ongoing-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tutorial-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "everyday-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "magnetic-italian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mature intelligent and highly charged melodrama unbelivebly filmed in China in 1948. wei wei's stunning performance as the catylast in a love triangle is simply stunning if you have the oppurunity to see this magnificent film take it\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-tractor",
   "metadata": {},
   "source": [
    "## Bag of words pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-horizon",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lovely-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hungarian-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(x_train):\n",
    "    words_in_documents = []\n",
    "    for document in x_train:\n",
    "        sentences = (sent_tokenize(document))\n",
    "        words = []\n",
    "        for sentence in sentences:\n",
    "            temp = word_tokenize(sentence)\n",
    "            final_words = [x for x in temp if x.isalnum()]\n",
    "            words.extend(final_words)\n",
    "        words_in_documents.append(words)\n",
    "    return words_in_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "received-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_documents = tokenise(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "removed-second",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_in_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "noted-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_test_documents = tokenise(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-aircraft",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "subtle-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "variable-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deadly-stage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'not' in sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "grateful-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.discard('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "collective-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'not' in sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "running-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.add(\"br\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "combined-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.add(\"http\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "optimum-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwards(words_in_documents, sws):\n",
    "    final_words_in_documents = []\n",
    "    for text in words_in_documents:\n",
    "        useful_words = [w.lower() for w in text if w.lower() not in sws]\n",
    "        final_words_in_documents.append(useful_words)\n",
    "    return final_words_in_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "brief-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_documents = remove_stopwards(words_in_documents, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "painted-iraqi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_in_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "higher-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_test_documents = remove_stopwards(words_in_test_documents, sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-thanksgiving",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "municipal-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "differential-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "antique-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(stemmer, documents):\n",
    "    final_documents = []\n",
    "    for document in documents:\n",
    "        useful_words = [stemmer(w) for w in document if not w.isdigit()]\n",
    "        final_documents.append(useful_words)\n",
    "    return final_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "powerful-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_documents = stemming(ps.stem,words_in_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "polished-telephone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_in_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "flush-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_test_documents = stemming(ps.stem,words_in_test_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-finance",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "occupational-faculty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = x_train.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "altered-shift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "Npos = np.count_nonzero(y_train=='pos')\n",
    "Nneg = np.count_nonzero(y_train=='neg')\n",
    "print(Npos+Nneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "solar-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_pos = Npos/N\n",
    "P_neg = Nneg/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "killing-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_size(documents):\n",
    "    vocab = set()\n",
    "    count=0\n",
    "    for document in documents:\n",
    "        for w in document:\n",
    "            if w not in vocab:\n",
    "                vocab.add(w)\n",
    "                count+=1\n",
    "    return count\n",
    "vocab = vocab_size(words_in_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "failing-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pos = {}\n",
    "d_neg = {}\n",
    "for i in range(N):\n",
    "    if y_train[i]==\"pos\":\n",
    "        for w in words_in_documents[i]:\n",
    "            d_pos[w] = d_pos.get(w,0)+1\n",
    "    else:\n",
    "        for w in words_in_documents[i]:\n",
    "            d_neg[w] = d_neg.get(w,0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "assisted-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words_pos = 0\n",
    "count_words_neg = 0\n",
    "temp_pos = set()\n",
    "temp_neg = set()\n",
    "for i in range(N):\n",
    "    if y_train[i]==\"pos\":\n",
    "        for word in words_in_documents[i]:\n",
    "            if word not in temp_pos:\n",
    "                temp_pos.add(word)\n",
    "                count_words_pos+=1\n",
    "    else:\n",
    "        for word in words_in_documents[i]:\n",
    "            if word not in temp_neg:\n",
    "                temp_neg.add(word)\n",
    "                count_words_neg+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "serious-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(X,c):\n",
    "    temp = set()\n",
    "    countc=0\n",
    "    L = 1\n",
    "    if c==\"pos\":\n",
    "        countc = count_words_pos\n",
    "        for w in X:\n",
    "            countwc = d_pos.get(w,0)\n",
    "            num = countwc+1\n",
    "            denom = countc+vocab\n",
    "            L*=100*num/denom\n",
    "        Pc = P_pos\n",
    "    else:\n",
    "        countc = count_words_neg\n",
    "        for w in X:\n",
    "            countwc = d_neg.get(w,0)\n",
    "            num = countwc+1\n",
    "            denom = countc+vocab\n",
    "            L*=100*num/denom\n",
    "        Pc = P_neg\n",
    "    return L*Pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sonic-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.307628363622563e-21"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior(words_in_documents[1233],\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "passive-asian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005877058373650559"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior(words_in_documents[1233],\"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "detailed-quality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "involved-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for document in words_in_test_documents:\n",
    "    if posterior(document,\"pos\")>=posterior(document,\"neg\"):\n",
    "        predicted.append(\"pos\")\n",
    "    else:\n",
    "        predicted.append(\"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "compliant-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = [int(i) for i in range(len(words_in_test_documents))]\n",
    "d = {\"Id\":Id, \"label\":predicted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "wrapped-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "saving-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"Result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-combine",
   "metadata": {},
   "source": [
    "### Accuracy on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "second-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for document in words_in_documents:\n",
    "    if posterior(document,\"pos\")>=posterior(document,\"neg\"):\n",
    "        predicted.append(\"pos\")\n",
    "    else:\n",
    "        predicted.append(\"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "civilian-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.array(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "intellectual-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.count_nonzero(predicted==y_train)/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "irish-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890525\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-reset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
